--- 
title: "Python编写Hadoop MapReduce程序"
type: post
layout: post
tags: 
- MapReduce
- Python
---
<p>尽管Hadoop的整个framework是使用Java实现的，但并不是一定要用java才能编写MapReduce程序。</p> <p><strong>Hadoop Streaming</strong> is a utility which allow users to create and run jobs with any executables as the mapper and/or the reducer.</p> <p><strong>Hadoop Pipes</strong> is a SWIG-compatible C++ API to implement MapReduce applications.</p> <p>我们可以使用几乎任何语言编写可执行的mapper和reducer程序，通过使用 Hadoop Streaming 工具，在hadoop上实现我们自己的MapReduce编程。</p> <p>Apache Hadoop给出的python实现MR例子是通过Jython实现的，把Jython代码编译成jar文件，本质还是基于java.</p> <p>下面给出一个纯Python实现MapReduce的例子，通过Hadoop Streaming调用/执行Python代码：</p> <p>1. 编写mapper</p> <div> <ol> <li> <div><span>#!/usr/bin/env python</span></div> <li> <div> </div> <li> <div><span>import</span> <span>sys</span></div> <li> <div> </div> <li> <div><span>for</span> line <span>in</span> <span>sys</span>.<span>stdin</span>:</div> <li> <div>    line = line.<span>strip</span><span>(</span><span>)</span></div> <li> <div>    words = line.<span>split</span><span>(</span><span>)</span></div> <li> <div>    <span>for</span> word <span>in</span> words:</div> <li> <div>        <span>print</span> <span>'%s<span>t</span>%s'</span> <span>%</span><span>(</span>word,<span>1</span><span>)</span></div></li></ol></div> <p>2. 编写reducer</p> <div> <ol> <li> <div><span>#!/usr/bin/env python</span></div> <li> <div> </div> <li> <div><span>from</span> <span>operator</span> <span>import</span> itemgetter</div> <li> <div><span>import</span> <span>sys</span></div> <li> <div> </div> <li> <div>word2count = <span>{</span><span>}</span></div> <li> <div> </div> <li> <div><span>for</span> line <span>in</span> <span>sys</span>.<span>stdin</span>:</div> <li> <div>    line = line.<span>strip</span><span>(</span><span>)</span></div> <li> <div>    word,count = line.<span>split</span><span>(</span><span>'<span>t</span>'</span>,<span>1</span><span>)</span></div> <li> <div>    <span>try</span>:</div> <li> <div>        count = <span>int</span><span>(</span>count<span>)</span></div> <li> <div>        word2count<span>[</span>word<span>]</span> = word2count.<span>get</span><span>(</span>word,<span>0</span><span>)</span>+count</div> <li> <div>    <span>except</span> <span>ValueError</span>:</div> <li> <div>        <span>pass</span></div> <li> <div> </div> <li> <div><span>for</span> word <span>in</span> word2count:</div> <li> <div>    <span>print</span> <span>'%s<span>t</span>%s'</span> <span>%</span><span>(</span>word,word2count<span>[</span>word<span>]</span><span>)</span></div></li></ol></div> <p>3. 测试mapper及reducer</p> <blockquote> <p>echo <span>"foo  linux unix gentoo debian linux foo test unix  bar quux"</span> | /home/hadoop/mapper.py | sort | /home/hadoop/reducer.py</p></blockquote> <p>4. 部署数据至HDFS</p> <blockquote> <p>下载几个纯文本内容的电子书放置在hadoop/tmp目录下</p> <p>将文件部署到HDFS(命名为textinput):</p> <p>./bin/hadoop dfs -copyFromLocal /tmp textinput</p></blockquote> <p>5. 使用Streaming工具运行Mapper及Reducer程序</p> <blockquote> <p>./bin/hadoop jar contrib/streaming/hadoop-*-streaming.jar<br />-mapper /home/hadoop/mapper.py -reducer /home/hadoop/reducer.py -input testinput<br />-output textoutput</p> <p>输出为textoutput </p></blockquote> <p>6. 查看运行结果  <blockquote> <p>结果存储在HDFS中：  <p>./bin/hadoop dfs -ls textoutput  <p><img style="margin: 3px 10px 5px 0px" src="http://i1218.photobucket.com/albums/dd413/nourlcn/wordpressblog/hadoop_single_mode_output.png" />  <p>./bin/hadoop dfs -cat textoutput/part-00000  <p><img style="margin: 3px 10px 5px 0px" src="http://i1218.photobucket.com/albums/dd413/nourlcn/wordpressblog/hadoop-mr-python-output2.png" width="510" height="261" /></p> <p>输出结果，统计每个单词出现的次数.</p></blockquote> <p>本文程序比较简单，参考了网上众多的资料.</p>
